{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/othmaneio/opt/miniconda3/envs/adaexam/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community.community_louvain as community_louvain\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "combined_df = pd.read_csv('/Users/othmaneio/Documents/financial_big_data/combined_stock_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_market_data(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate stock data into market-level features for each minute.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Polars DataFrame containing stock data with necessary columns.\n",
    "    \n",
    "    Returns:\n",
    "    - market_data: Polars DataFrame with aggregated market-level features.\n",
    "    \"\"\"\n",
    "    market_data = (\n",
    "        df.group_by('minute')\n",
    "        .agg([\n",
    "            # Price volatility (standard deviation of weighted trade prices)\n",
    "            pl.col('weighted_trade_price').std().alias('price_volatility'),\n",
    "\n",
    "            # Return volatility (volume-weighted standard deviation of returns)\n",
    "            (\n",
    "                (pl.col('return') * pl.col('total_trade_volume'))\n",
    "                .sum()\n",
    "                / pl.col('total_trade_volume').sum()\n",
    "            ).alias('avg_return'),\n",
    "            pl.col('return').std().alias('return_volatility'),\n",
    "\n",
    "            \n",
    "\n",
    "            # Trade volume statistics\n",
    "            pl.col('total_trade_volume').mean().alias('avg_trade_volume'),\n",
    "            pl.col('total_trade_volume').std().alias('volume_volatility'),\n",
    "\n",
    "            # Average bid-ask spread\n",
    "            ((pl.col('weighted_ask_price') - pl.col('weighted_bid_price')).mean())\n",
    "            .alias('avg_spread'),\n",
    "\n",
    "            # Proportion of advancing stocks (positive returns)\n",
    "            (pl.col('return') > 0).mean().alias('advancing_stocks'),\n",
    "        ])\n",
    "        .fill_null(0)  # Replace null values with 0\n",
    "    )\n",
    "\n",
    "    # Ensure the results are sorted by minute\n",
    "    market_data = market_data.sort('minute')\n",
    "\n",
    "    return market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare market features\n",
    "combined_df = pl.DataFrame(combined_df)\n",
    "market_data = calculate_market_data(combined_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7_820, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>minute</th><th>price_volatility</th><th>avg_return</th><th>return_volatility</th><th>avg_trade_volume</th><th>volume_volatility</th><th>avg_spread</th><th>advancing_stocks</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2010-05-03 09:30:00-04:00&quot;</td><td>44.178432</td><td>0.004845</td><td>0.005309</td><td>397540.447619</td><td>2.9211e6</td><td>0.180964</td><td>0.627907</td></tr><tr><td>&quot;2010-05-03 09:31:00-04:00&quot;</td><td>42.087616</td><td>0.00036</td><td>0.002905</td><td>147834.982906</td><td>894941.945331</td><td>0.116104</td><td>0.6</td></tr><tr><td>&quot;2010-05-03 09:32:00-04:00&quot;</td><td>44.210426</td><td>-0.002906</td><td>0.00259</td><td>271919.94958</td><td>2.4171e6</td><td>0.077482</td><td>0.529915</td></tr><tr><td>&quot;2010-05-03 09:33:00-04:00&quot;</td><td>43.771961</td><td>-0.004586</td><td>0.002798</td><td>210191.362903</td><td>1.9084e6</td><td>0.088461</td><td>0.596774</td></tr><tr><td>&quot;2010-05-03 09:34:00-04:00&quot;</td><td>44.20407</td><td>-0.000179</td><td>0.001869</td><td>315054.5</td><td>3.0612e6</td><td>0.077935</td><td>0.5</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2010-05-28 15:56:00-04:00&quot;</td><td>30.515974</td><td>-0.002326</td><td>0.000879</td><td>66782.308943</td><td>194534.002545</td><td>0.02457</td><td>0.00813</td></tr><tr><td>&quot;2010-05-28 15:57:00-04:00&quot;</td><td>36.84272</td><td>-0.001509</td><td>0.000694</td><td>123828.325397</td><td>513753.591724</td><td>0.031873</td><td>0.007937</td></tr><tr><td>&quot;2010-05-28 15:58:00-04:00&quot;</td><td>30.250318</td><td>-0.001353</td><td>0.000703</td><td>90634.046875</td><td>299053.569279</td><td>0.022169</td><td>0.03125</td></tr><tr><td>&quot;2010-05-28 15:59:00-04:00&quot;</td><td>30.312197</td><td>-0.000508</td><td>0.000916</td><td>216019.84252</td><td>1.2109e6</td><td>0.029367</td><td>0.251969</td></tr><tr><td>&quot;2010-05-28 16:00:00-04:00&quot;</td><td>47.16607</td><td>-0.000845</td><td>0.001893</td><td>644464.564103</td><td>2.0233e6</td><td>2.084197</td><td>0.435897</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7_820, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ minute     ┆ price_vola ┆ avg_return ┆ return_vo ┆ avg_trade ┆ volume_vo ┆ avg_sprea ┆ advancing │\n",
       "│ ---        ┆ tility     ┆ ---        ┆ latility  ┆ _volume   ┆ latility  ┆ d         ┆ _stocks   │\n",
       "│ str        ┆ ---        ┆ f64        ┆ ---       ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆ f64        ┆            ┆ f64       ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2010-05-03 ┆ 44.178432  ┆ 0.004845   ┆ 0.005309  ┆ 397540.44 ┆ 2.9211e6  ┆ 0.180964  ┆ 0.627907  │\n",
       "│ 09:30:00-0 ┆            ┆            ┆           ┆ 7619      ┆           ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-03 ┆ 42.087616  ┆ 0.00036    ┆ 0.002905  ┆ 147834.98 ┆ 894941.94 ┆ 0.116104  ┆ 0.6       │\n",
       "│ 09:31:00-0 ┆            ┆            ┆           ┆ 2906      ┆ 5331      ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-03 ┆ 44.210426  ┆ -0.002906  ┆ 0.00259   ┆ 271919.94 ┆ 2.4171e6  ┆ 0.077482  ┆ 0.529915  │\n",
       "│ 09:32:00-0 ┆            ┆            ┆           ┆ 958       ┆           ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-03 ┆ 43.771961  ┆ -0.004586  ┆ 0.002798  ┆ 210191.36 ┆ 1.9084e6  ┆ 0.088461  ┆ 0.596774  │\n",
       "│ 09:33:00-0 ┆            ┆            ┆           ┆ 2903      ┆           ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-03 ┆ 44.20407   ┆ -0.000179  ┆ 0.001869  ┆ 315054.5  ┆ 3.0612e6  ┆ 0.077935  ┆ 0.5       │\n",
       "│ 09:34:00-0 ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …         ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 2010-05-28 ┆ 30.515974  ┆ -0.002326  ┆ 0.000879  ┆ 66782.308 ┆ 194534.00 ┆ 0.02457   ┆ 0.00813   │\n",
       "│ 15:56:00-0 ┆            ┆            ┆           ┆ 943       ┆ 2545      ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-28 ┆ 36.84272   ┆ -0.001509  ┆ 0.000694  ┆ 123828.32 ┆ 513753.59 ┆ 0.031873  ┆ 0.007937  │\n",
       "│ 15:57:00-0 ┆            ┆            ┆           ┆ 5397      ┆ 1724      ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-28 ┆ 30.250318  ┆ -0.001353  ┆ 0.000703  ┆ 90634.046 ┆ 299053.56 ┆ 0.022169  ┆ 0.03125   │\n",
       "│ 15:58:00-0 ┆            ┆            ┆           ┆ 875       ┆ 9279      ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-28 ┆ 30.312197  ┆ -0.000508  ┆ 0.000916  ┆ 216019.84 ┆ 1.2109e6  ┆ 0.029367  ┆ 0.251969  │\n",
       "│ 15:59:00-0 ┆            ┆            ┆           ┆ 252       ┆           ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-05-28 ┆ 47.16607   ┆ -0.000845  ┆ 0.001893  ┆ 644464.56 ┆ 2.0233e6  ┆ 2.084197  ┆ 0.435897  │\n",
       "│ 16:00:00-0 ┆            ┆            ┆           ┆ 4103      ┆           ┆           ┆           │\n",
       "│ 4:00       ┆            ┆            ┆           ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sparse_similarity_lazyframe(feature_df: pl.DataFrame, threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Create a sparse similarity matrix with optimization for large datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - feature_df: Polars DataFrame containing the features.\n",
    "    - threshold: Minimum similarity value to include in the sparse matrix.\n",
    "\n",
    "    Returns:\n",
    "    - LazyFrame with columns [row, col, similarity].\n",
    "    \"\"\"\n",
    "    # Select features and handle NaNs\n",
    "    clustering_features = [\n",
    "        'price_volatility',\n",
    "        'return_volatility',\n",
    "        'avg_return',\n",
    "        'avg_trade_volume',\n",
    "        'volume_volatility',\n",
    "        'advancing_stocks',\n",
    "        'avg_spread'\n",
    "    ]\n",
    "    features = feature_df.select(clustering_features).to_numpy()\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create a Polars DataFrame with scaled features\n",
    "    scaled_df = pl.DataFrame(features_scaled, schema=clustering_features)\n",
    "\n",
    "    # Generate sparse row combinations\n",
    "    indices = list(combinations(range(len(scaled_df)), 2))\n",
    "\n",
    "    # Compute similarity only for selected pairs\n",
    "    similarities = []\n",
    "    for i, j in indices:\n",
    "        dot_product = np.dot(features_scaled[i], features_scaled[j])\n",
    "        norm_i = np.linalg.norm(features_scaled[i])\n",
    "        norm_j = np.linalg.norm(features_scaled[j])\n",
    "        similarity = dot_product / (norm_i * norm_j)\n",
    "        if similarity > threshold:\n",
    "            similarities.append((i, j, similarity))\n",
    "    \n",
    "    # Create a Polars LazyFrame from sparse matrix\n",
    "    sparse_df = pl.DataFrame(similarities, schema=[\"row\", \"row_other\", \"similarity\"]).lazy()\n",
    "    return sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slf = create_sparse_similarity_lazyframe(market_data, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import networkx as nx\n",
    "import community.community_louvain as community_louvain\n",
    "\n",
    "def identify_market_states(similarity_lazyframe: pl.LazyFrame):\n",
    "    \"\"\"\n",
    "    Perform Louvain clustering using a precomputed sparse similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - similarity_lazyframe: Polars LazyFrame with columns [row, row_other, similarity].\n",
    "\n",
    "    Returns:\n",
    "    - Polars DataFrame with cluster assignments for each node.\n",
    "    \"\"\"\n",
    "    # Collect the LazyFrame into a DataFrame for processing\n",
    "    similarity_df = similarity_lazyframe.collect()\n",
    "\n",
    "\n",
    "\n",
    "    # Create a graph from the sparse similarity matrix\n",
    "    G = nx.Graph()\n",
    "    for row in similarity_df.iter_rows(named=True):\n",
    "        G.add_edge(row['row'], row['row_other'], weight=row['similarity'])\n",
    "\n",
    "    print('Graph created')\n",
    "    # Perform Louvain clustering\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "\n",
    "    # Convert the partition dictionary to a Polars DataFrame\n",
    "    clusters_df = pl.DataFrame(\n",
    "        {\"node\": list(partition.keys()), \"cluster\": list(partition.values())}\n",
    "    )\n",
    "\n",
    "    return G, clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph created\n"
     ]
    }
   ],
   "source": [
    "market_states = identify_market_states(slf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = market_states[0]\n",
    "market_states = market_states[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the cluster assignments with the original dataset\n",
    "\n",
    "\n",
    "market_features_pd = market_data.to_pandas().reset_index(names=\"node\")\n",
    "market_states_pd = market_states.to_pandas()\n",
    "\n",
    "linked_data= pd.merge(market_features_pd, market_states_pd, on=\"node\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>minute</th>\n",
       "      <th>price_volatility</th>\n",
       "      <th>avg_return</th>\n",
       "      <th>return_volatility</th>\n",
       "      <th>avg_trade_volume</th>\n",
       "      <th>volume_volatility</th>\n",
       "      <th>avg_spread</th>\n",
       "      <th>advancing_stocks</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-03 09:30:00-04:00</td>\n",
       "      <td>44.178432</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>397540.447619</td>\n",
       "      <td>2.921071e+06</td>\n",
       "      <td>0.180964</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-03 09:31:00-04:00</td>\n",
       "      <td>42.087616</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>147834.982906</td>\n",
       "      <td>8.949419e+05</td>\n",
       "      <td>0.116104</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-03 09:32:00-04:00</td>\n",
       "      <td>44.210426</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>271919.949580</td>\n",
       "      <td>2.417100e+06</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-05-03 09:33:00-04:00</td>\n",
       "      <td>43.771961</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>210191.362903</td>\n",
       "      <td>1.908430e+06</td>\n",
       "      <td>0.088461</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-05-03 09:34:00-04:00</td>\n",
       "      <td>44.204070</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>315054.500000</td>\n",
       "      <td>3.061200e+06</td>\n",
       "      <td>0.077935</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node                     minute  price_volatility  avg_return  \\\n",
       "0     0  2010-05-03 09:30:00-04:00         44.178432    0.004845   \n",
       "1     1  2010-05-03 09:31:00-04:00         42.087616    0.000360   \n",
       "2     2  2010-05-03 09:32:00-04:00         44.210426   -0.002906   \n",
       "3     3  2010-05-03 09:33:00-04:00         43.771961   -0.004586   \n",
       "4     4  2010-05-03 09:34:00-04:00         44.204070   -0.000179   \n",
       "\n",
       "   return_volatility  avg_trade_volume  volume_volatility  avg_spread  \\\n",
       "0           0.005309     397540.447619       2.921071e+06    0.180964   \n",
       "1           0.002905     147834.982906       8.949419e+05    0.116104   \n",
       "2           0.002590     271919.949580       2.417100e+06    0.077482   \n",
       "3           0.002798     210191.362903       1.908430e+06    0.088461   \n",
       "4           0.001869     315054.500000       3.061200e+06    0.077935   \n",
       "\n",
       "   advancing_stocks  cluster  \n",
       "0          0.627907        1  \n",
       "1          0.600000        3  \n",
       "2          0.529915        1  \n",
       "3          0.596774        1  \n",
       "4          0.500000        1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGGREGRATE FEATURES PER STATE\n",
    "combined_df = combined_df.astype({'minute': 'str', 'stock': 'str'})\n",
    "cdf = pd.merge(combined_df, linked_data[['minute', 'cluster']], on='minute')\n",
    "cdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
